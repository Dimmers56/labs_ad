{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c076d17f-75cd-4868-bf9d-f25bfbea5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3643657f-40e8-4279-8407-32096e3079c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Дані оновлені. Новий файл: noaa_data\\obl_1_15032025131332.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_2_15032025131333.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_3_15032025131337.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_4_15032025131339.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_5_15032025131341.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_6_15032025131342.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_7_15032025131343.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_8_15032025131344.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_9_15032025131345.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_10_15032025131348.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_11_15032025131349.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_12_15032025131350.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_13_15032025131351.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_14_15032025131352.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_15_15032025131353.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_16_15032025131355.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_17_15032025131356.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_18_15032025131357.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_19_15032025131358.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_20_15032025131359.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_21_15032025131400.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_22_15032025131401.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_23_15032025131403.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_24_15032025131404.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_25_15032025131405.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_26_15032025131406.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_27_15032025131409.csv\n",
      " Дані оновлені. Новий файл: noaa_data\\obl_28_15032025131411.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_DIR = \"noaa_data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "def download_vhi(province_id):\n",
    "    url = f\"https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php?country=UKR&provinceID={province_id}&year1=1981&year2=2024&type=Mean\"\n",
    "\n",
    "    try:\n",
    "        wp = urllib.request.urlopen(url)\n",
    "        text = wp.read().decode(\"utf-8\")\n",
    "        from io import StringIO\n",
    "        headers = ['Year', 'Week', 'SMN', 'SMT', 'VCI', 'TCI', 'VHI', 'empty']\n",
    "        new_data = pd.read_csv(StringIO(text), header = 1,  names = headers, sep=\",\")\n",
    "\n",
    "        existing_files = glob.glob(os.path.join(DATA_DIR, f\"obl_{province_id}_*.csv\"))\n",
    "        if existing_files:\n",
    "            existing_file = existing_files[0]  \n",
    "            old_data = pd.read_csv(existing_file, header = 1, names = headers)\n",
    "\n",
    "            if new_data.equals(old_data):\n",
    "                print(f\" Дані для області {province_id} не змінилися. Файл залишився без змін.\")\n",
    "                return\n",
    "\n",
    "            os.remove(existing_file)\n",
    "\n",
    "        current_datetime = datetime.now().strftime(\"%d%m%Y%H%M%S\")\n",
    "        new_file_path = os.path.join(DATA_DIR, f\"obl_{province_id}_{current_datetime}.csv\")\n",
    "\n",
    "        new_data.to_csv(new_file_path, index=False)\n",
    "        print(f\" Дані оновлені. Новий файл: {new_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Помилка при завантаженні області {province_id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, 29):\n",
    "    province_id = i\n",
    "    download_vhi(province_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4dd10e-fe0d-48c8-8c28-8b37836d6cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Завантажено 28 файлів.\n",
      "   Province_ID  Year  Week    SMN     SMT    VCI    TCI    VHI  empty\n",
      "0           10  1982   2.0  0.063  261.53  55.89  38.20  47.04    NaN\n",
      "1           10  1982   3.0  0.063  263.45  57.30  32.69  44.99    NaN\n",
      "2           10  1982   4.0  0.061  265.10  53.96  28.62  41.29    NaN\n",
      "3           10  1982   5.0  0.058  266.42  46.87  28.57  37.72    NaN\n",
      "4           10  1982   6.0  0.056  267.47  39.55  30.27  34.91    NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_vhi_data(directory):\n",
    "    all_files = [f for f in os.listdir(directory) if f.startswith(\"obl_\") and f.endswith(\".csv\")]\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"Немає файлів для завантаження!\")\n",
    "        return None\n",
    "    \n",
    "    dataframes = []\n",
    "    \n",
    "    for file in all_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        headers = ['Year', 'Week', 'SMN', 'SMT', 'VCI', 'TCI', 'VHI', 'empty']\n",
    "        df = pd.read_csv(file_path, header = 1, names = headers)\n",
    "        \n",
    "        \n",
    "        province_id = int(file.split(\"_\")[1])\n",
    "        df.insert(0, \"Province_ID\", province_id)\n",
    "        \n",
    "        dataframes.append(df)\n",
    "    \n",
    "    final_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(\"Завантажено\", len(all_files), \"файлів.\")\n",
    "    return final_df\n",
    "\n",
    "DATA_DIR = \"noaa_data\"\n",
    "df_vhi = load_vhi_data(DATA_DIR)\n",
    "if df_vhi is not None:\n",
    "    print(df_vhi.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415c6696-40e5-4f40-a017-29b40068336b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_vhi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mГотово!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mhead())  \n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 14\u001b[0m df_vhi \u001b[38;5;241m=\u001b[39m rename_province_ids(df_vhi)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_vhi' is not defined"
     ]
    }
   ],
   "source": [
    "def rename_province_ids(df):\n",
    "    province_mapping = {\n",
    "        1: 13, 2: 14, 3: 15, 4: 16, 5: 17, 6: 18, 7: 19, 8: 20,\n",
    "        9: 21, 10: 22, 11: 23, 12: 24, 13: 1, 14: 2, 15: 3, 16: 4,\n",
    "        17: 5, 18: 6, 19: 7, 20: 8, 21: 9, 22: 10, 23: 11, 24: 12,\n",
    "        25: 25  \n",
    "    }\n",
    "    \n",
    "    df[\"Province_ID\"] = df[\"Province_ID\"].replace(province_mapping)\n",
    "    \n",
    "    print(\"Готово!\\n\", df.head())  \n",
    "    return df\n",
    "\n",
    "df_vhi = rename_province_ids(df_vhi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d845d8b-8b68-4e6b-976c-c7e7bcaf2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vhi_by_year(df, province_id, year):\n",
    "    return df[(df[\"Province_ID\"] == province_id) & (df[\"Year\"] == year)]\n",
    "def get_extremes(df, province_ids, years):\n",
    "    df_vhi[\"Year\"] = pd.to_numeric(df_vhi[\"Year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    subset = df[(df[\"Province_ID\"].isin(province_ids)) & (df[\"Year\"].isin(years))]\n",
    "    return {\n",
    "        \"min\": subset[\"VHI\"].min(),\n",
    "        \"max\": subset[\"VHI\"].max(),\n",
    "        \"mean\": subset[\"VHI\"].mean(),\n",
    "        \"median\": subset[\"VHI\"].median()\n",
    "    }\n",
    "def get_vhi_by_year_range(df, province_ids, start_year, end_year):\n",
    "    return df[(df[\"Province_ID\"].isin(province_ids)) & (df[\"Year\"].between(start_year, end_year))]\n",
    "\n",
    "def find_drought_years(df, threshold=5):\n",
    "    drought_years = []\n",
    "    for year in df[\"Year\"].unique():\n",
    "        yearly_data = df[df[\"Year\"] == year]\n",
    "        drought_regions = yearly_data[yearly_data[\"VHI\"] < 15][\"Province_ID\"].unique()\n",
    "        if len(drought_regions) >= threshold:\n",
    "            drought_years.append((year, drought_regions))\n",
    "    return drought_years"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
